[
  {
    "path": "posts/2024-02-27-dashboard-pemilu-2024-desa-bujung-sari-marga/",
    "title": "Transformative 2024 Election Dashboard for Bujung Sari Marga Village",
    "description": "The 2024 Election Dashboard for Bujung Sari Marga Village is an interactive platform presenting the latest data and information related to the 2024 General Election in Bujung Sari Marga Village. With an informative and user-friendly interface, this dashboard allows residents to monitor the progress, results, and data analysis of the election after the counting process is completed, supporting active participation of the community in the local democratic process.",
    "author": [
      {
        "name": "Agus Santoso",
        "url": {}
      }
    ],
    "date": "2024-02-27",
    "categories": [
      "Looker Studio",
      "Google Data Studio",
      "Election Data",
      "Data Visualizations"
    ],
    "contents": "\nIntroductions\nIn response to the need for timely and transparent information regarding the 2024 General Election in Bujung Sari Marga Village, the creation of the Election Dashboard has been initiated. This interactive platform aims to provide residents with up-to-date data and insights into the election process, enabling them to monitor results and analyze voting trends after the counting process is completed. The user-friendly interface is designed to facilitate active community engagement in the democratic process at the local level.\nWhat Tools To Use\nLooker Studio\nSpreadsheets\nPreparations\nHere, I want to describe a few tools in this analysis:\nConnect the data from Spreadsheets to Looker Studio\nTools/Functions we use:\nFiltering\nTabular Data\nData Viz\netc\n\nVisualizations and Analysis\nData visualization on the dashboard is seamlessly presented through intuitive graphs, charts, and interactive visual elements. These visual representations offer a clear and comprehensive view of the 2024 General Election data for Bujung Sari Marga Village. Users can easily interpret trends, analyze voting patterns, and gain valuable insights, fostering a deeper understanding of the electoral dynamics within the community.\nThe dashboard categorizes data into five distinct types of votes, starting from the Presidential and Vice Presidential (PWP) election, followed by the House of Representatives (DPR RI), Regional Representative Council (DPD), Provincial Legislative Council (DPRD-Provinsi), and District/City Legislative Council (DPRD-Kabupaten/Kota), providing a detailed breakdown of the electoral process.\nDashboard Presidential and Vice Presidential (PWP) Election\nThe dashboard provides a detailed analysis of votes cast for the Presidential and Vice Presidential candidates, offering insights into the preferences and trends shaping the leadership choices within Bujung Sari Marga Village. We can see it as dashboard details and preview in Fig. 1 below.\nFig. 1. Presidential and Vice Presidential (PWP).Dashboard House of Representatives (DPR RI)\nUsers can explore the data related to the election of representatives to the national House of Representatives, allowing for a comprehensive understanding of the political landscape and representation preferences at the national level. We can see it as dashboard details and preview in Fig. 2 below.\nFig. 2. Dashboard House of Representatives (DPR RI).Dashboard Regional Representative Council (DPD)\nThe dashboard highlights the voting patterns for the Regional Representative Council, providing valuable insights into the community’s choices for representatives at the regional level. We can see it as dashboard details and preview in Fig. 3 below.\nFig. 3. Regional Representative Council (DPD).Dashboard Provincial Legislative Council (DPRD-Provinsi)\nDetailed visualizations on the dashboard illustrate the electoral dynamics for the Provincial Legislative Council, offering a breakdown of votes and preferences at the provincial level. We can see it as dashboard details and preview in Fig. 4 below.\nFig. 4. Provincial Legislative Council (DPRD-Provinsi).Dashboard District/City Legislative Council (DPRD-Kabupaten/Kota)\nFor a localized perspective, the dashboard presents a comprehensive breakdown of votes for the District/City Legislative Council, enabling residents to examine the choices and trends in their specific administrative areas. We can see it as dashboard details and preview in Fig. 5 below.\nFig. 5. District/City Legislative Council (DPRD-Kabupaten/Kota).Conclusion\nAs we conclude this interactive journey through the 2024 General Election Dashboard for Bujung Sari Marga Village, we invite you to explore the rich tapestry of data and insights it offers. The breakdown of votes across the five categories, from the Presidential and Vice Presidential election to the District/City Legislative Council, provides a nuanced understanding of our community’s democratic choices. This platform is not just a tool for post-election analysis but a testament to our commitment to transparency and informed civic participation. As we navigate through the visualizations, may we gain a deeper appreciation for the diverse voices that shape our local democracy. Your engagement with this dashboard contributes to the collective knowledge and strengthens the foundation of our shared democratic values. Thank you for being an active participant in shaping the future of Bujung Sari Marga Village.\n\nTHANK YOU 🙌\n\n\n\n\n",
    "preview": "posts/2024-02-27-dashboard-pemilu-2024-desa-bujung-sari-marga/surasulu2024.jpeg",
    "last_modified": "2024-02-28T09:16:43+07:00",
    "input_file": "dashboard-pemilu-2024-desa-bujung-sari-marga.knit.md"
  },
  {
    "path": "posts/2023-10-03-utilizing-health-tech-device-usage-trends-to-inform-marketing-strategy-bellabeat-analysis/",
    "title": "Utilizing Health Tech Device Usage Trends to Inform Marketing Strategy: Bellabeat Analysis",
    "description": "To analyze smart device data to gain insight into how consumers are using their smart devices.",
    "author": [
      {
        "name": "Agus Santoso",
        "url": {}
      }
    ],
    "date": "2023-10-03",
    "categories": [
      "Python",
      "Data Visualizations",
      "Marketing Analysis"
    ],
    "contents": "\nIntroductions\nScenario\nWelcome to the Bellabeat data analysis case study! In this case study, I will perform many real-world tasks of a junior data analyst. I will imagine I am working for Bellabeat, a high-tech manufacturer of health-focused products for women, and meet different characters and team members. In order to answer the key business questions, you will follow the steps of the data analysis process: ask, prepare, process, analyze, share, and act.\n\nFig. 1. Bellabeat Leaf’s.\nI am a junior data analyst working on the marketing analyst team at Bellabeat, a high-tech manufacturer of health-focused products for women. Bellabeat is a successful small company, but they have the potential to become a larger player in the global smart device market. Urška Sršen, cofounder and Chief Creative Officer of Bellabeat, believes that analyzing smart device fitness data could help unlock new growth opportunities for the company. I have been asked to focus on one of Bellabeat’s products and analyze smart device data to gain insight into how consumers are using their smart devices. The insights I discover will then help guide marketing strategy for the company. I will present your analysis to the Bellabeat executive team along with your high-level recommendations for Bellabeat’s marketing strategy.\nWhat Tools To Use\nGoogle Colaboratory\nPython\nExploratory Data Analytics\nGoogle Colaboratory\nImport Libraries Python: pandas, numpy, matplotlib, etc.\nThis public dataset in here\nConnect with the data\nConnect the data\nThe first step is that we have to make sure our data is connected.\n\n#Connect google colab with my drive\nfrom google.colab import drive\ndrive.mount(\"/content/drive\")\n\nImport and Reading Data\nImport libraries\nImport libraries we need to use, like:\n\n#import libraries all we need\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random as random\nimport plotly.graph_objects as go\nfrom plotly.offline import iplot\nfrom plotnine.data import economics\nfrom plotnine import ggplot, aes, geom_line\nimport warnings\n\nRead the data\nRead the data\n\n#import the data we use\ndaily_activity  = pd.read_csv(\"/content/drive/MyDrive/Fitabase Dataset/dailyActivity_merged.csv\")\ndaily_calories = pd.read_csv(\"/content/drive/MyDrive/Fitabase Dataset/dailyCalories_merged.csv\")\nsleep_day  = pd.read_csv(\"/content/drive/MyDrive/Fitabase Dataset/sleepDay_merged.csv\")\nweight_log_info  = pd.read_csv(\"/content/drive/MyDrive/Fitabase Dataset/weightLogInfo_merged.csv\")\n\nData Understandings\nBasic data understandings\nThis is basic data understandings like:\nDataFrame : df.\nshape : df.shape()\nhead : df.head()\ninfo : df.info()\ndescribe : df.describe()\nData Processing\nInformations of Dataset\nIn the first step of data processing we can use several database understandings to see an overview of the dataset to data type information and check for the duplicates values.\nBreakdown the data to make analysis easier\nDaily Activity Dataset\n\ndaily_activity.head() # View the data\ndaily_activity.describe() # View the descriptive statistics or overview the dataset\nddaily_activity.info() # View the info from data like data type and others\nprint(daily_activity.shape) # Provide the number of rows and columns in the dataset\nlist(daily_activity) # View list of column names\ndaily_activity.drop_duplicates() # Check for the duplicates values\ndaily_activity.shape\nprint(daily_activity.isnull().sum()) # Print the number of null values in each column\n\nFixing Error\nSecond step is fixing error form the data\nChange the data type if something is wrong\n\nFixing Error from data type ActivityDay –> from object to date\n\n#Change the data type from object to date\ndaily_activity['ActivityDate'] = pd.to_datetime(daily_activity['ActivityDate'])\n\nCreate/Adding New Columns\n\n# Create year column\ndaily_activity['Year'] = daily_activity['ActivityDate'].dt.year\n\n# Create month column\ndaily_activity['Month'] = daily_activity['ActivityDate'].dt.month\n\n# Create day column\ndaily_activity['Day'] = daily_activity['ActivityDate'].dt.day\n\n# Create day_of_week column\ndaily_activity['Day_of_week'] = daily_activity['ActivityDate'].dt.day_name()\n\nCheck again the data info\n\ndaily_activity.info()\ndaily_activity.head()\n\ncheck the information after change data type and adding the data with daily_activity.info() and daily_activity.head(). Details like the image below.\n\nFig. 2. Screenshot daily_activity.info()\nNoted: Do the same for daily_calories, sleep_day, and weight_log_info adjusted to the dataset. If all the required datasets have been prepared and processed, you can proceed to the next step.\nDesign Visualizations\nHeatmap Correlations\n\nplt.figure(figsize=(14,14))\nsns.heatmap(daily_activity.corr(), cmap='Greens', annot=True,)\nplt.show()\n\nAverage Activity Minutes\n\n# List of activity types to calculate the mean for\nactivity_types = ['VeryActiveMinutes', 'FairlyActiveMinutes', 'LightlyActiveMinutes', 'SedentaryMinutes']\n\n# Calculate the average values for each activity type across all days\naverage_activity = daily_activity[activity_types].mean()\n\n# Create labels and values for the pie chart\nactivity_labels = average_activity.index\nactivity_minutes = average_activity.values\n\n# Create the pie chart\nplt.figure(figsize=(8, 8))\nplt.pie(activity_minutes, labels=activity_labels, autopct='%1.1f%%', startangle=140)\nplt.title('Average Activity Minutes')\nplt.show()\n\nTotal Very Active Minutes During Each Day\n\n# Create a specific order for days of the week\ndays_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n\n# Group and sum the Very Active Minutes for each day\nveryactive_minutes = daily_activity.groupby('Day_of_week').agg({'VeryActiveMinutes': 'sum'}).reindex(days_order).reset_index()\n\n# Set the figure size\na1 = (8, 6)\nfig, ax = plt.subplots(figsize=a1)\n\n# Create the bar plot\nplot = sns.barplot(x=\"Day_of_week\", y=\"VeryActiveMinutes\", data=veryactive_minutes, palette=\"deep\")\n\n# Rotate x-axis labels for better readability\nplot.set_xticklabels(ax.get_xticklabels(), rotation=90)\n\n# Set the title and labels\nplot.set_title('Total Very Active Minutes by Days')\nax.set_ylabel('Total VeryActiveMinutes Sum')\nax.set_xlabel('Days')\n\nTotal Sedentary Minutes During Each Day\n\n# Create a specific order for days of the week\ndays_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n\n# Group and sum the SedentaryMinutes for each day\nsedentary_minutes = daily_activity.groupby('Day_of_week').agg({'SedentaryMinutes': 'sum'}).reindex(days_order).reset_index()\n\n# Set the figure size\na1 = (8, 6)\nfig, ax = plt.subplots(figsize=a1)\n\n# Create the bar plot\nplot = sns.barplot(x=\"Day_of_week\", y=\"SedentaryMinutes\", data=sedentary_minutes, palette=\"deep\")\n\n# Rotate x-axis labels for better readability\nplot.set_xticklabels(ax.get_xticklabels(), rotation=90)\n\n# Set the title and labels\nplot.set_title('Total Sedentary Minutes by Days')\nax.set_ylabel('Total SedentaryMinutes Sum')\nax.set_xlabel('Days')\n\nTotal Steps\n\n# Create a specific order for days of the week\ndays_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n\n# Group and sum the TotalSteps for each day\ntotalsteps_days = daily_activity.groupby('Day_of_week').agg({'TotalSteps': 'sum'}).reindex(days_order).reset_index()\n\n# Set the figure size\na1 = (8, 6)\nfig, ax = plt.subplots(figsize=a1)\n\n# Create the bar plot\nplot = sns.barplot(x=\"Day_of_week\", y=\"TotalSteps\", data=totalsteps_days, palette=\"deep\")\n\n# Rotate x-axis labels for better readability\nplot.set_xticklabels(ax.get_xticklabels(), rotation=90)\n\n# Set the title and labels\nplot.set_title('Total Steps by Days')\nax.set_ylabel('Total Steps Sum')\nax.set_xlabel('Days')\n\nTotal Distance During Each Day\n\n# Create a specific order for days of the week\ndays_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n\n# Group and sum the TotalDistance for each day\nsedentary_minutes = daily_activity.groupby('Day_of_week').agg({'TotalDistance': 'sum'}).reindex(days_order).reset_index()\n\n# Set the figure size\na1 = (8, 6)\nfig, ax = plt.subplots(figsize=a1)\n\n# Create the bar plot\nplot = sns.barplot(x=\"Day_of_week\", y=\"TotalDistance\", data=sedentary_minutes, palette=\"deep\")\n\n# Rotate x-axis labels for better readability\nplot.set_xticklabels(ax.get_xticklabels(), rotation=90)\n\n# Set the title and labels\nplot.set_title('Total Distance by Days')\nax.set_ylabel('Total Distance Sum')\nax.set_xlabel('Days')\n\nTotal Steps and Total Distance by Day of Week\n\n# Create a figure and the primary y-axis\nfig, ax1 = plt.subplots(figsize=(10, 6))\nsns.barplot(x='Day_of_week', y='TotalSteps', data=daily_activity, label='Total Steps', color='skyblue', ax=ax1)\n\n# Calculate a scaling factor for Total Distance\ntotal_distance_max = daily_activity['TotalDistance'].max()\nscaling_factor = daily_activity['TotalSteps'].max() / total_distance_max\n\n# Plot Total Distance (scaled) on the secondary y-axis\ndaily_activity['TotalDistance_scaled'] = daily_activity['TotalDistance'] * scaling_factor\nsns.barplot(x='Day_of_week', y='TotalDistance_scaled', data=daily_activity, label='Total Distance', color='salmon', ax=ax1)\n\n# Customize the plot\nplt.title('Total Steps and Total Distance by Day of Week')\nax1.set_xlabel('Day of Week')\nax1.set_ylabel('Count')\nplt.grid(True)\n\n# Show the plot\nplt.tight_layout()\nplt.show()\n\nRelationship between Total Steps and Calories\n\n# Create a scatter plot using Seaborn\nplt.figure(figsize=(10, 6))\nsns.scatterplot(data=daily_activity, x=\"TotalSteps\", y=\"Calories\", hue=\"SedentaryMinutes\", palette=\"coolwarm\", alpha=0.7)\nplt.xlabel(\"Total Steps\")\nplt.ylabel(\"Calories\")\nplt.title(\"Relationship between Total Steps and Calories\")\nplt.grid(True)\n\n# Add a regression line (similar to geom_smooth in ggplot2)\nsns.regplot(data=daily_activity, x=\"TotalSteps\", y=\"Calories\", scatter=False, color=\"gray\")\n\nplt.show()\n\nTotal Minutes A Sleep During Each Day\n\nsd_days = sleep_day.groupby('Day_of_week').agg({'TotalMinutesAsleep':'sum'}).reset_index().sort_values('TotalMinutesAsleep',ascending = False)\n\na1 = (8, 6)\nfig, ax = plt.subplots(figsize=a1)\nplot= sns.barplot(x=\"Day_of_week\", y=\"TotalMinutesAsleep\", data=sd_days,palette =\"deep\")\nplot.set_xticklabels(ax.get_xticklabels(),rotation=90)\nplot.set_title('Total Minutes A Sleep During Each Day')\nax.set_ylabel('Total Minutes A Sleep')\nax.set_xlabel('Days')\n\nPercentage of People in Each BMI Category\n\n# Define BMI categories based on thresholds\ndef categorize_bmi(bmi):\n    if bmi < 18.5:\n        return 'Underweight'\n    elif 18.5 <= bmi < 24.9:\n        return 'Healthy Weight'\n    elif 25 <= bmi < 29.9:\n        return 'Overweight'\n    else:\n        return 'Obese'\n\n# Apply the categorization to the BMI column\nweight_log_info['BMI Category'] = weight_log_info['BMI'].apply(categorize_bmi)\n\n# Calculate the percentage of individuals in each BMI category\ncategory_counts = weight_log_info['BMI Category'].value_counts(normalize=True) * 100\n\n# Create a pie chart or a bar chart\nplt.figure(figsize=(8, 8))\nplt.pie(category_counts, labels=category_counts.index, autopct='%1.1f%%', startangle=140)\nplt.title('Percentage of People in Each BMI Category')\nplt.axis('equal')  # Equal aspect ratio ensures the pie chart is circular.\n\n# Show the chart\nplt.show()\n\nWeight Distribution (Kg)\n\n# Histogram for WeightKg\nplt.figure(figsize=(10, 6))\nsns.histplot(data=weight_log_info, x='WeightKg', bins=20, kde=True)\nplt.title('Weight Distribution (Kg)')\nplt.xlabel('Weight (Kg)')\nplt.ylabel('Frequency')\nplt.show()\n\nVisualizations and Analysis\nHeatmaps Correlations\nA correlation heatmap is a graphical representation of a correlation matrix representing the correlation between different variables. The value of correlation can take any value from -1 to 1. Correlation between two random variables or bivariate data does not necessarily imply a causal relationship. We can see it as in Fig. 3 below 👇\nFig. 3. Heatmaps Correlations.Average Actvity Minutes\nThe pie chart displays the distribution of active minutes across four categories: Very Active Minutes, Fairly Active Minutes, Lightly Active Minutes, Sedentary Minutes. We can see it as details in Fig. 4 below.\nFig. 4. Average Activity Minutes.The data extracted from the pie chart concerning average activity minutes paints a striking picture of user habits. It becomes immediately apparent that the vast majority of users, approximately 81.3%, tend to spend a substantial portion of their daily routines in sedentary minutes activities. This is a significant concern as prolonged periods of inactivity can have adverse effects on overall health. Conversely, the chart also reveals a rather alarming statistic: a mere 1.7% of users actively engage in very active minutes.\nTotal Very Active Minutes During Each Day\nIn our analysis of the Bellabeat dataset, we examined the distribution of ‘Very Active Minutes’ across different days of the week.\nFig. 5. Total Very Active Minutes by Days.This analysis provides valuable insights into user behavior and engagement patterns. It is evident that users tend to accumulate more ‘Very Active Minutes’ during weekdays, with Tuesday standing out as the days when users are most active. This may suggest that users prioritize physical activity during the early part of the week. Interestingly, the activity level starts to decline as we progress towards the weekend, with Friday and Sunday showing lower ‘Very Active Minutes’ on average but saturday but Fridays seeing a slight increase.\nTotal Sedentary Minutes During Each Day\nThe bar chart displays the distribution of Sedentary Minutes. We can see it as details in Fig. 6 below.\nFig. 6. Total Sedentary Minutes by Days.The graph, our findings reveal an interesting trend where users tend to have higher ‘Sedentary Minutes’ during weekdays, with Tuesday showing the highest levels of sedentary behavior. This pattern may be indicative of typical workweek routines, where individuals spend prolonged periods sitting at desks or engaging in less active tasks. As the week progresses, there is a decline in sedentary behavior until the end of the week.\nTotal Steps\nThe bar graph shows that the highest total steps were on Tuesday and decreased towards the weekend, but there was a jump on Saturday and decreased again on Sunday. We can see it as details in Fig. 7 below.\nFig. 7. Total Steps by DaysTotal Distance During Each Day and Total Steps with Total Distance by Day of Week\nThe bar graph show with Total Distance highest on Tuesday. We can see it as details in Fig. 8 below.\nFig. 8. Total Distance Each Day.The bar graph show with Total Distance and Total Steps During Each Day.\nFig. 9. Total Steps and Total Distance by Day of Week.Relationship between Total Steps and Calories Burned\nIn our exploration of the Bellabeat dataset, we uncovered a fascinating relationship between ‘Total Steps’ and ‘Calories Burned.’ While the conventional wisdom suggests that more steps lead to more calories burned, our analysis revealed a counter intuitive trend. We observed that certain users, classified as sedentary due to their minimum step count, were still able to burn a significant number of calories, often falling within the range of 1500 to 2500 calories. In contrast, some more active users, who took significantly more steps, burned calories in a similar range. We can see it as details in Fig. 10 below.\nFig. 10. Relationship between Total Steps and Calories.In this case we assume the possibility exists that factors beyond step count, such as metabolism, basal metabolic rate, or the intensity of activities, play a substantial role in calorie expenditure.\nTotal Minutes A Sleep During Each Day\nThe bar graph show with Total Minutes A Sleep During Each Day highest on Wednesday. We can see it as details in Fig. 11 below.\nFig. 11. Total Minutes A Sleep During Each Day.Percentage of People in Each BMI Category\nWithin our dataset by randomly adding the contents of the ‘Fat’ column we obtained,\n\nFixing Error with Missing Values (NaN)\nNotes: The NA value is detected in the Fat section. I am going to fill the NA values based on the avaliable ones.\n\nweight_log_info['Fat'].value_counts()\n22.0    1\n25.0    1\nName: Fat, dtype: int64\n\n#Replace the missing 'Fat' values by values between 22 and 25\nweight_log_info['Fat'] = weight_log_info['Fat'].apply(lambda x: random.randint(22, 25))\n\nweight_log_info['Fat'].value_counts()\noutput\n23    21\n22    16\n24    16\n25    14\nName: Fat, dtype: int64\n\noutput, 23 = 21 column, 22 = 16 column, 24 = 16 column, 25 = 14 column. We can see it as details in Fig. 12 below.\nFig. 12. Screenshot Fill NaN ValuesWithin our dataset, a noteworthy observation emerges: a majority of individuals, comprising 50.7%, are classified as being within the healthy weight range. This percentage is notably higher than the 47.8% of individuals categorized as overweight and the 1.5% who fall into the obese category. We can see it as details in Fig. 13 below.\nFig. 13. Percentage of People in Each BMI Category.This data underscores a compelling opportunity for health promotion initiatives aimed at encouraging and facilitating individuals to achieve and maintain a healthy weight. Such initiatives can play a pivotal role in enhancing overall public health by reducing the prevalence of overweight and obesity, both of which are associated with various health risks and conditions.\nWeight Distribution\nIn our analysis of the Bellabeat dataset, we generated a histogram to gain insights into the distribution of weights among users, as represented by the ‘WeightKg’ variable. The histogram provides a visual representation of the frequency or count of individuals falling within different weight ranges. We can see it as details in Fig. 14 below.\nFig. 14. Weight Distribution.Upon examination, we observed a bell-shaped distribution, suggesting that the majority of users have weights clustered around a central value. This central tendency in weight is a common characteristic of populations, with most individuals maintaining weights close to the average.\nFurthermore, the histogram revealed that the dataset includes a range of weights, from the lower end to the higher end of the scale. This diversity in weight distribution is essential for tailoring health and fitness recommendations to address the unique needs of individuals with varying weight profiles.\nOverall, the ‘WeightKg’ histogram serves as a valuable tool for understanding the weight distribution within the dataset and can inform strategies for promoting and supporting healthy weight management among users.\nConclusion\nThis analysis provides valuable insights into user behavior and engagement patterns.\nIn ‘Very Active Minutes’ it is clear that users tend to accumulate more ‘Very Active Minutes’ during weekdays, with Tuesday standing out as the days when users are most active. This may suggest that users prioritize physical activity during the early part of the week.\nIn our exploration, we uncovered a fascinating relationship between ‘Total Steps’ and ‘Calories Burned.’ While the conventional wisdom suggests that more steps lead to more calories burned, our analysis revealed a counter intuitive trend. We observed that certain users, classified as sedentary due to their minimum step count, were still able to burn a significant number of calories, often falling within the range of 1500 to 2500 calories.\nWithin our dataset, a noteworthy observation emerges about Percentage of People in Each BMI Category: a majority of individuals, comprising 50.7%, are classified as being within the healthy weight range. This percentage is notably higher than the 47.8% of individuals categorized as overweight and the 1.5% who fall into the obese category.\nObservations\nThe Bellabeat dataset is a comprehensive health and fitness dataset that includes fitness tracking, sleep patterns, total steps, calories, even weight. This makes it a valuable resource for individuals who want to make informed decisions about their health.\nRecomendations\nBellabeat has the capability to notify users regarding their inactive lifestyle through either the mobile app or directly on the fitness tracker. Given that a significant 81.3% of users do not currently utilize the device for monitoring their health routines, this data could prove highly valuable for devising effective marketing strategies.\n\nTHANK YOU 🙌\n\n\n\n\n",
    "preview": "posts/2023-10-03-utilizing-health-tech-device-usage-trends-to-inform-marketing-strategy-bellabeat-analysis/leaf_urban_rose_gold05.jpeg",
    "last_modified": "2023-10-05T19:36:12+07:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-09-29-nycairbnb-data-analytics-case-study/",
    "title": "NYC AirBnB Data Analytics Case Study",
    "description": "Identify a marketplace that connects people renting houses with people looking for a place to stay.",
    "author": [
      {
        "name": "Agus Santoso",
        "url": {}
      }
    ],
    "date": "2023-09-29",
    "categories": [
      "Python",
      "Data Visualizations",
      "Marketing Analysis"
    ],
    "contents": "\nIntroductions\nThis personal project is a case study given by RevoU in a mini course held for 2 weeks to see the participants’ understanding of the Data Analytics material that has been presented, therefore I tried to make several analyzes of this Airbnb which is a marketplace that connects people who renting out houses to people looking for a place to stay.\nWhat Tools To Use\nGoogle Colaboratory\nPython\nSummary\n\nFig. 1. Te Kahu, Wanaka, New Zealand\nAirbnb is an online marketplace that connects people who want to rent out their homes with people looking for accommodations in specific locales. The company has come a long way since 2007, when its co-founders first came up with the idea to invite paying guests to sleep on an air mattress in their living room. According to Airbnb’s latest data, it now has more than 7 million listings, covering some 100,000 cities and towns in 220-plus countries and regions worldwide.\nExploratory Data Analytics\nPreparation\nGoogle Colaboratory\nImport Libraries Python: pandas, numpy, matplotlib\nThis public dataset is part of Airbnb, This is New York City Airbnb Open Data from Dgomonov.\nConnect with the data\nConnect the data\nThe first step is that we have to make sure our data is connected.\n\n# Connect with dataset in drive\nfrom google.colab import drive\ndrive.mount(\"/content/drive\")\n\nImport and Reading Data\nImport libraries\nImport libraries we need to use, like:\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random as random\nimport random\nfrom datetime import datetime, timedelta\nimport plotly.express as px\nimport warnings\n\nRead the data\nRead the data\n\n# Read the data\ndf = pd.read_csv(\"/content/drive/MyDrive/dataset nyc airbnb/AB_NYC_2019.csv\")\n\nData Understandings\nBasic data understandings\nThis is basic data understandings like:\nDataFrame : df.\nshape : df.shape()\nhead : df.head()\ninfo : df.info()\ndescribe : df.describe()\nData Processing\nInformations of Dataset\nIn the first step of data processing we can use several database understandings to see an overview of the dataset to data type information and check for the duplicates values.\n\ndf.head() # View the data\ndf.describe() # View the descriptive statistics or overview the dataset\ndf.info() # View the info from data like data type and others\nprint(df.shape) # Provide the number of rows and columns in the dataset\nlist(df) # View list of column names\ndf.drop_duplicates() # Check for the duplicates values\ndf.shape\nprint(df.isnull().sum()) # Print the number of null values in each column\n\nFixing Error\nSecond step is fixing error form the data\nChange the data type if something is wrong\n\n# Change the data type from object to date\ndf['last_review'] = pd.to_datetime(df['last_review'])\ndf['review_year'] = df['last_review'].apply(lambda last_review:last_review.year)\ndf['review_year'] = df['review_year'].fillna(0)\ndf['review_year'] = df.review_year.astype(int)\ndf = pd.concat([df[(df['availability_365']==0) & (df['review_year']==2019)],df[df['availability_365']>0]])\n\nReplace missing values\n\n#Replace the missing value with 0\ndf['reviews_per_month'] = df['reviews_per_month'].fillna(0)\n\nCheck again the data info\n\ndf.info()\n\nFixing again if there is still something you want to fix\nhere i want to drop data last_review and eplace the missing ‘name’ values by random name.\n\n# Drop the 'last_review' column\ndf.drop('last_review', axis=1, inplace=True)\n\n# Replace the missing 'name' values by random name\ndf = df.fillna({'name': 'Upper East Side Oasis!'}) # here i fill with 'Upper East Side Oasis!'\ndf = df.fillna({'host_name': 'john'}) # here i fill with 'john'\n\nView the dataset\nview the dataset with df.head() and df.info() and check too dataset isnull.\n\ndf.head()\ndf.info()\nprint(df.isnull().sum())\n\nDesign Visualizations\nHeatmap Correlations\nCorrelation heatmaps are here to show us how closely related variables are.\n\nplt.figure(figsize=(12,12))\nsns.heatmap(df.corr(), cmap='Blues', annot=True,)\nplt.show()\n\nCount of Room Types by Neighbourhood Group\nTo see room type by neighbourhood group\n\n# Create the count plot\nplt.figure(figsize=(10, 10))\nsns.set(style=\"whitegrid\")\n# Create a count plot with 'room_type' on the x-axis and hue='neighbourhood_group'\nsns.countplot(data=df, x='room_type', hue='neighbourhood_group', palette='viridis')\nplt.title('Count of Room Types by Neighbourhood Group')\n# Show the plot\nplt.show()\n\nBar plot\nTo shows Proportion of Airbnb listings across boroughs and room type.\n\n# Create a bar plot borough\n(df['neighbourhood_group'].value_counts() / df.shape[0]).plot.bar(cmap='tab10', title='Proportion of Airbnb listings across boroughs')\nplt.xlabel('Borough')\nplt.ylabel('Proportion')\nplt.xticks(rotation=45)\nplt.show()\n\n# Create a bar plot room type\n(df['room_type'].value_counts() / df.shape[0]).plot.bar(cmap='tab10', title='Proportion of Airbnb listings across room_type')\nplt.xlabel('Room Type')\nplt.ylabel('Proportion')\nplt.xticks(rotation=45)\nplt.show()\n\nMost Expensive\nTo see where is the most expensive area?\n\n# Create the bar plot\nfig = sns.catplot(x='neighbourhood_group', y='price', data=df, kind='bar', hue='room_type', palette='viridis')\n# Add a title and adjust its position\nfig.fig.suptitle('Where is the most expensive area?', fontsize=15, y=1.05)\n# Save the plot as an image with tight layout\nfig.savefig('most_expensive_area.png', bbox_inches='tight')\n\nPopular area?\nTo see where is the most popular area based on availability?\n\n# Create the bar plot\nplt.figure(figsize=(10, 6))\nsns.set(style=\"whitegrid\")\n# Sort the DataFrame by 'availability_365' in descending order\ndf_sorted = df.sort_values(by='availability_365', ascending=False)\n# Create the bar plot\nsns.boxplot(data=df_sorted, x='neighbourhood_group', y='availability_365', palette='viridis')\nplt.xlabel('Neighbourhood Group')\nplt.ylabel('Availability (in days)')\nplt.title('Most Popular Neighbourhood Group Based on Availability')\n# Show the plot\nplt.show()\n\nMap Box\nNext, we can visualize it using a box map to see the distribution.\n\n# Visualize Map Box with scatterplot\nplt.figure(figsize=(10,10))\nsns.scatterplot(x='longitude', y='latitude', hue='neighbourhood_group',s=20, data=df, palette=\"viridis\")\n\nTop 5 Host Listing\nTo see who the top 5 by calculated_host_listings_count\n\n# Calculate total reviews per host\ntotal_host_listings_count = df.groupby('host_name')['calculated_host_listings_count'].sum()\n# Rank hosts by total listings count\nranked_hosts = total_host_listings_count.sort_values(ascending=False)\n# Top 5 host_names based on total listings count\ntop_5_host_names = ranked_hosts.head(5)\n# Display the top 5 host_names\nprint(top_5_host_names)\n\n# Create a bar plot to visualize the top 5 host_names by total listings\nplt.figure(figsize=(10, 6))\nplt.bar(top_5_host_names.index, top_5_host_names.values, color='skyblue')\nplt.xlabel('Host Name')\nplt.ylabel('Total Listings')\nplt.title('Top 5 Hosts by Total Listings')\nplt.xticks(rotation=45)\nplt.tight_layout()\n\n# Show the plot\nplt.show()\n\nVisualizations and Analysis\nHeatmaps Correlations\nA correlation heatmap is a graphical representation of a correlation matrix representing the correlation between different variables. The value of correlation can take any value from -1 to 1. Correlation between two random variables or bivariate data does not necessarily imply a causal relationship. We can see it as in Fig. 2 below 👇\nFig. 2. Heatmaps Correlations.Count of Room Types by Neighbourhood Group\nTo create an analysis of this, we first collected data from Airbnb listings and created Airbnb areas based on neighborhood groups such as: Manhattan, Bronx, Brooklyn, Queens, and Staten Island. We then calculated three main room types: Whole house/apartment, Shared room, and Private room in each neighborhood group. We can see the details in Fig. 3.\nFig. 3. Count of Room Types by Neighbourhood GroupThe results indicate that Manhattan has the highest number of Entire home/apt listings, reflecting its popularity as a tourist destination. Brooklyn follows closely behind, offering a mix of room types. In contrast, the Bronx, Queens, and Staten Island have a higher proportion of Entire home/apt and Private rooms, likely due to their residential nature.\nProportion of Airbnb listings across boroughs and room_type\nThis is Breakdown from Count of Room Types by Neighbourhood Group\nProportion of Airbnb listings across boroughs\nIn this analysis, we explore the distribution of Airbnb listings across the five major boroughs of New York City: Manhattan, Bronx, Brooklyn, Queens, and Staten Island. We can see details in Fig. 4.\nFig. 4. Proportion of Airbnb Listings Across Boroughs.Regarding boroughs in this graph Fig. 4., Manhattan and Brooklyn have the highest proportions of Airbnb listings, reflecting their status as top tourist destinations. Queens also boasts a significant number of listings, while the Bronx offers a more affordable alternative. Staten Island, with its suburban appeal, has the smallest share of Airbnb listings among the five boroughs.\nProportion of Airbnb listings across room_type\nIn addition to region, We explored the Airbnb listing distribution of three room types in New York City: Entire home/apt, Private room, and Shared room. We can see details in Fig. 5.\nFig. 5. Proportions of Airbnb Listings Across Room Type.In terms of room types, Airbnb listings in New York City predominantly comprise “Entire home/apt” options, catering to those seeking privacy and convenience. “Private room” listings come next, offering a balance between affordability and comfort. “Shared room” listings are the least common, serving budget-conscious solo travelers or those comfortable sharing living spaces.\nWhere The Most Expensive Area?\nTo analyze the data, we first gathered information on rental prices for these room types in each borough. Afterward, we calculated the average rental price for each combination of borough and room type. Here are the findings:\nManhattan: Unsurprisingly, Manhattan emerges as the most expensive borough overall, with entire homes/apartments being the costliest, followed by private rooms and shared rooms.\nBronx: In the Bronx, shared rooms are the most affordable option, followed by private rooms and entire homes/apartments.\nBrooklyn: Brooklyn exhibits a similar pattern to Manhattan, with entire homes/apartments being the most expensive, followed by private rooms and shared rooms.\nQueens: Queens generally offers more affordable accommodations compared to Manhattan and Brooklyn. Entire homes/apartments are the priciest, followed by private rooms and shared rooms.\nStaten Island: Staten Island, being the least expensive of the five boroughs, sees private rooms as the most economical choice, followed by shared rooms and entire homes/apartments.\nTo visualize these findings, we’ve created bar graphs below that represent the average rental prices for each borough and room type. These graphs will help you better understand the price distribution across the different areas and accommodation types. We can see details in Fig. 6.\nFig. 6. The Most Expensive Area.Please note that the specific rental prices can vary greatly within each borough, and this analysis provides a general overview. If you have access to the relevant data, you can create more detailed analyses and visuals to dive deeper into the specific neighborhoods and factors influencing rental prices in each area.\nMost Popular Neighbourhood Group Based On Availability?\nThe box plot analysis depicts the availability of Airbnb listings in the five major boroughs of New York City (Manhattan, Bronx, Brooklyn, Queens, and Staten Island). The ‘availability_365’ metric is used to measure the availability of listings throughout the year. We can see the details in Fig. 7.\nFig. 7. The Most Popular Area Based On Availability.Looking at the above categorical box plot we can infer that the listings in State Island seems to be more available throughout the year to more than 300 days. On an average, these listings are available to around more 250 days every year followed by Bronx where every listings are available for around more 150 on an average every year.\nLet’s also see Map Box Distributions\nFig. 8. Map Box Distributions.Mapbox distribution in New York City shows varying levels of usage across the five boroughs: Manhattan, Bronx, Brooklyn, Queens, and Staten Island. In Manhattan, where the bustling heart of the city resides, Mapbox is likely to see high utilization, with its mapping and location services catering to the demands of businesses, tourists, and residents alike.\nTop 5 Host Listing\nTo find Top 5 hosts by total listings count.\nFig. 9. Top 5 Host Listings.As we can find that Top 5 host name are Sonder (NYC), Blueground, Kara, Kazuya, and Sonder.\nConclusion\nThe results indicate that Manhattan has the highest number of Entire home/apt listings, reflecting its popularity as a tourist destination. Brooklyn follows closely behind, offering a mix of room types. In contrast, the Bronx, Queens, and Staten Island have a higher proportion of Entire home/apt and Private rooms, likely due to their residential nature.\nWe can infer that there are high range of prices across Manhattan followed by Brooklyn and Queens being the most costliest place to stay in NYC.\nUnderstanding these proportions can assist travelers in selecting accommodations that suit their preferences and budgets.\nObservations\nManhattan has the highest number of Entire home/apt listings, reflecting its popularity as a tourist destination. Brooklyn follows closely behind, offering a mix of room types. Then Manhattan have more expensive places to stay in NYC. Room availability is very low in manhattan and brooklyn and you can find a room anytime in the State Island and Bronx.\nRecomendations\nIf you are looking for the most expensive locations you can come to Manhattan and Brooklyn or Queens. However, if you want to find the places with the highest availability in New York City, you can choose a location like the Bronx with an average of more than 150 days every year or State Island with an average of more than 250 days available every year.\n\nTHANK YOU 🙌\n\n\n\n\n",
    "preview": "posts/2023-09-29-nycairbnb-data-analytics-case-study/luxury_airbnb.webp",
    "last_modified": "2023-10-03T11:47:23+07:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-09-24-timesheet-monitoring-tracker/",
    "title": "TimeSheet Monitoring Tracker",
    "description": "A TimeSheet Monitoring Tracker to track the working hours performed by the intern employees.",
    "author": [
      {
        "name": "Agus Santoso",
        "url": {}
      }
    ],
    "date": "2023-09-24",
    "categories": [
      "Spreadsheets",
      "Monitoring Tracker",
      "Data Visualizations"
    ],
    "contents": "\nIntroductions\nThis project is undertaken due to the people team’s and mentor need to track the working hours performed by the intern employees during their work activities on a weekly basis. This is to observe the performance patterns of the interns.\nWhat Tools To Use\nSpreadsheets\nSCQA Framework\nHere’s the SCQA Frameworks we use:\nSituation:\nThere is a working hour regulation for interns, which is currently set at 40 hours per week.\nThere is a discussion about changing the working hour regulation with two options: 30 hours per week or 15 hours per week.\nThe Campaign has implemented a work deliverables sheet in the commitment form, which serves as evidence of data regarding the tasks and working hours of interns every day.\nComplication:\nThe implementation of work deliverables has not been optimal due to the difficulty in monitoring, both by mentors and the people team.\nFeedback from some interns indicates that it is not very effective due to excessive administrative work, such as the obligation to fill out standup.ly and Jira tasks.\nAs a result, data related to the average working hours of interns per week cannot be compiled.\nQuestion:\nHow can we monitor and track the working hours of interns along with the tasks/projects they are working on?\nAnswer:\nTime/Task/Project Sheet Tracker\nModify the existing work deliverables sheet to create a sheet/form that is visually easier for interns to fill out.\nMentors can more easily monitor and provide feedback on a weekly/monthly basis.\nWorking hour data can be pulled by the people team, ensuring that interns comply with their choice of working hours (30 or 15 hours per week).\nPreparations\nHere, I want to describe a few tools in this analysis:\nSpreadsheets\nTools/Functions we use:\nFiltering\nSlicer\nImportrange\nFormating\nIF Functions\netc\n\nFiles : I want to know you Data files are hidden due to company secrets.\nStep and Plan\nCreate Template Work Deliverables Sheet\nCreate a new template with modifications from the previous sheet. This template will later be duplicated by each intern, then the data in the work deliverables sheet will be pulled into the Time Sheet Tracker (people-team data center). Heres the picture Work Deliverables Sheet Template.\n\nFig. 1. Template Work Deliverables Sheet.\nTimeSheet Monitoring Tracker\nCreate a TimeSheet Monitoring Tracker (Central Data). In the time sheet tracker there will be 4 sections:\nGuidlines: Contains How to Use the TimeSheet Monitoring Tracker\n\nFig. 2. Guidlines Tracker\nPeople Team Monitoring: Contains a total recap of internal work deliverables such as total working hours per week per intern.\n\nFig. 3. People Team Monitoring Tracker\nMentor Monitoring: Recap of internal work deliverables per team, to make it easier for mentors to check without having to open internal deliverables one by one.\n\nFig. 4. Mentor Monitoring Tracker\nData-Viz: To see a graph of the development of internal working hours.\n\nFig. 5. Data Vizualization Monitoring Tracker\nTrial and Error\nAfter the work deliverables sheets and TimeSheet Monitoring Tracker are created, we carry out the next step, namely by Trial & Error to finding out of the best way to reach a desired result or a correct solution by trying out one or more ways or means and by noting and eliminating errors or causes of failure.\nEvaluations\nEvaluation needs to be carried out to assess or calculate the quality of the TimeSheet Monitoring Tracker that we have developed. We can do this with all the data that has been collected since TimeSheet Monitoring Tracker was used.\nFinalization\nIn the last step we finalize it after all the steps have been carried out and the TimeSheet Monitoring Tracker can be used properly.\n\n\n\n",
    "preview": "posts/2023-09-24-timesheet-monitoring-tracker/mt-peopleteam.png",
    "last_modified": "2023-09-29T15:38:04+07:00",
    "input_file": {},
    "preview_width": 1440,
    "preview_height": 900
  }
]
